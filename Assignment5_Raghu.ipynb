{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4fOhbcTJh4aTnEtEid074",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghuram1999/IT1703/blob/main/Assignment5_Raghu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing the data and splitting into training and testing sets:"
      ],
      "metadata": {
        "id": "v2EtkJk_6aI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZnpl78b3miz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "data = pd.read_csv('/content/real_estate_value.csv')\n",
        "\n",
        "\n",
        "X = data.drop('UnitPrice', axis=1)\n",
        "y = data['UnitPrice']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examining the data and preprocessing:"
      ],
      "metadata": {
        "id": "NxBDRzW76PFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Check data types\n",
        "print(data.dtypes)\n",
        "\n",
        "# Check for outliers and distribution\n",
        "print(data.describe())\n",
        "\n",
        "# Correlation analysis\n",
        "print(data.corr())\n",
        "\n",
        "# Preprocessing steps\n",
        "#  Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmP13VUq30Vd",
        "outputId": "a2c8cf57-69c4-425c-af06-039e28d16ed9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HouseAge         0\n",
            "DistanceToMRT    0\n",
            "NoOfStores       0\n",
            "Latitude         0\n",
            "Longitude        0\n",
            "UnitPrice        0\n",
            "dtype: int64\n",
            "HouseAge         float64\n",
            "DistanceToMRT    float64\n",
            "NoOfStores         int64\n",
            "Latitude         float64\n",
            "Longitude        float64\n",
            "UnitPrice        float64\n",
            "dtype: object\n",
            "         HouseAge  DistanceToMRT  NoOfStores    Latitude   Longitude  \\\n",
            "count  414.000000     414.000000  414.000000  414.000000  414.000000   \n",
            "mean    17.712560    1083.885689    4.094203   24.969030  121.533361   \n",
            "std     11.392485    1262.109595    2.945562    0.012410    0.015347   \n",
            "min      0.000000      23.382840    0.000000   24.932070  121.473530   \n",
            "25%      9.025000     289.324800    1.000000   24.963000  121.528085   \n",
            "50%     16.100000     492.231300    4.000000   24.971100  121.538630   \n",
            "75%     28.150000    1454.279000    6.000000   24.977455  121.543305   \n",
            "max     43.800000    6488.021000   10.000000   25.014590  121.566270   \n",
            "\n",
            "        UnitPrice  \n",
            "count  414.000000  \n",
            "mean    37.980193  \n",
            "std     13.606488  \n",
            "min      7.600000  \n",
            "25%     27.700000  \n",
            "50%     38.450000  \n",
            "75%     46.600000  \n",
            "max    117.500000  \n",
            "               HouseAge  DistanceToMRT  NoOfStores  Latitude  Longitude  \\\n",
            "HouseAge       1.000000       0.025622    0.049593  0.054420  -0.048520   \n",
            "DistanceToMRT  0.025622       1.000000   -0.602519 -0.591067  -0.806317   \n",
            "NoOfStores     0.049593      -0.602519    1.000000  0.444143   0.449099   \n",
            "Latitude       0.054420      -0.591067    0.444143  1.000000   0.412924   \n",
            "Longitude     -0.048520      -0.806317    0.449099  0.412924   1.000000   \n",
            "UnitPrice     -0.210567      -0.673613    0.571005  0.546307   0.523287   \n",
            "\n",
            "               UnitPrice  \n",
            "HouseAge       -0.210567  \n",
            "DistanceToMRT  -0.673613  \n",
            "NoOfStores      0.571005  \n",
            "Latitude        0.546307  \n",
            "Longitude       0.523287  \n",
            "UnitPrice       1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Justification for preprocessing steps:\n",
        "a) Checking for missing values: Ensure data completeness.\n",
        "\n",
        "b) Checking data types: Confirm all features are numerical.\n",
        "\n",
        "c) Outlier detection: Identify potential anomalies that might affect model performance.\n",
        "\n",
        "d) Correlation analysis: Understand relationships between features and the target variable.\n",
        "\n",
        "e) Standardization: Scale features to have zero mean and unit variance, which is important for many machine learning algorithms, especially when features are on different scales.\n",
        "\n"
      ],
      "metadata": {
        "id": "0tUDQmY45P38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning Decision Tree and Random Forest models:"
      ],
      "metadata": {
        "id": "cJw2H1v_6iAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "dt_params = {\n",
        "    'max_depth': [5, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt_grid = GridSearchCV(dt, dt_params, cv=5, scoring='neg_mean_squared_error')\n",
        "dt_grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error')\n",
        "rf_grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_model(model, X, y, model_name):\n",
        "    y_pred = model.predict(X)\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    r2 = r2_score(y, y_pred)\n",
        "    print(f\"{model_name} - MSE: {mse:.2f}, R2: {r2:.2f}\")\n",
        "\n",
        "# Decision Tree performance\n",
        "print(\"Decision Tree - Best parameters:\", dt_grid.best_params_)\n",
        "evaluate_model(dt_grid.best_estimator_, X_test_scaled, y_test, \"Decision Tree\")\n",
        "\n",
        "# Random Forest performance\n",
        "print(\"Random Forest - Best parameters:\", rf_grid.best_params_)\n",
        "evaluate_model(rf_grid.best_estimator_, X_test_scaled, y_test, \"Random Forest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SWeoYD83_3-",
        "outputId": "5b135103-cf16-46d1-91bb-8a99fd6d8c65"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
            "Decision Tree - MSE: 45.66, R2: 0.73\n",
            "Random Forest - Best parameters: {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
            "Random Forest - MSE: 32.73, R2: 0.80\n"
          ]
        }
      ]
    }
  ]
}